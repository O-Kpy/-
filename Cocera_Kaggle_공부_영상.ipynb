{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cocera Kaggle 공부 영상.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNEZtJ0Y8BingabPC+T3nYw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/O-Kpy/Machine-Learning-Lectures/blob/main/Cocera_Kaggle_%EA%B3%B5%EB%B6%80_%EC%98%81%EC%83%81.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LSXcZ0pDqj3"
      },
      "source": [
        "# 1주차\n",
        "\n",
        "ML을 할때 진행해야하는 process\n",
        "\n",
        "1. 비즈니스 관점으로 보기(ex 사용자에게 무엇을 제공할수있을지, 무엇을 할까...)\n",
        "2. 작업을 공식화 ==> 무엇을 예측해야하는가?, 어떤 데이터를 사용해야하는가?...\n",
        "3. 데이터 수집\n",
        "4. 데이터 처리(전,후처리)\n",
        "5. 데이터 저장\n",
        "6. 모델링\n",
        "7. 실제 시나리오에서 모델의 효과를 입증\n",
        "8. 모델 성능 모니터링, 새 데이터를 재교육하기\n",
        "\n",
        "\n",
        "\n",
        "> KNN은 신경망과 앙상블하면 안된다.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Feature Preprocessing, Feature Generating\n",
        "\n",
        "1. 데이터 결측값 채우기, (데이터 전처리...)\n",
        "2. Feature Preprocessing은 반드시 필요\n",
        "3. Feature Generating은 반드시 필요하진 않지만 데이터에 따라서 강력한 Tool이 될수있다.\n",
        "4. Feature Generation ==> 새 기능을 만드는 프로세스, 패턴을 발견해 새로운 컬럼을 추가 할 수 있다.\n",
        "\n",
        "> Numeric Features\n",
        "1. 스케일링(Scaling)(특히 KNN) - 데이터 분포를 고르게해주진 않는다.\n",
        "2. 이상치(Outlier)\n",
        "3. 순위(Rank)\n",
        "4. Numeric Features는 트리기반(스케일링에 의존하지 않는다.) 모델과 Non트리기반 모델과 다른 preprocessing 효과를 가진다.\n",
        "5. 로그(np.log(1+x))와 제곱근(np.sqrt(1+x)) 데이터 분포 변환, Regulization\n",
        "\n",
        "\n",
        "> Categorical Features\n",
        "1. 레이블 인코딩(원핫인코딩, 라벨인코딩, pandas.factorize(나오는 순서대로 인코딩)\n",
        "2. 피쳐 생성의 유용한 것 ==> 여러 분류 피쳐간의 피쳐 상호작용을 따라 피쳐를 생성\n",
        "3. 원핫 인코딩은 트리모델에서 시간이 너무 많이 걸림\n",
        "4. 두 개 이상의 고유 범주의 경우 원핫 인코딩이 안전 옵션이다. \n",
        "\n",
        "\n",
        " > Date and Time\n",
        " 1. 시계열데이터\n",
        " 2. 반복되는 패턴을 발견 할 수 있음 그리고 예측 할 수 있음\n",
        " 3. 주기 적용, 특정 이벤트 이후 전달된 시간 계산\n",
        "\n",
        "\n",
        " > Coordinates(좌표)\n",
        " 1. 거리(거리측정) 활용\n",
        " 2. 회전\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Missing Null (결측치 처리)\n",
        "너무 큰값, 음수(-)값(데이터에 따라), Nan, 999등...\n",
        "\n",
        "> 그냥 두기(무시) ==> 성능이 떨어질수있음, 중위수를 하기도 어려운 상황에서(상황마다 다르다)\n",
        "\n",
        "> 중위수(mean, median, mode)로 대체하기 ==> 선형, 신경망에서는 좋은 효과 but 트리모형에서는 안좋음\n",
        "\n",
        "> 예측값 집어넣기 ==> 일반화 오류가 생길수있음 \n",
        "\n",
        "> 피쳐 생성 전에 누락값을 채우지 말자 ==> 생성된 피쳐의 유용성이 안좋아진다.\n",
        "1. 먼저 피쳐 엔지니어링\n",
        "2. 그 다음 누락 값 채우기\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvaxkutO6GFs"
      },
      "source": [
        "# 2주차\n",
        "Building intuition about the data\n",
        " > 데이터의 도메인 지식 알아보기(배경지식)\n",
        " \n",
        " > 데이터가 어떻게 생성되었는지 알아보기 ==> test set이 train set을 잘 대표해야 하기 때문\n",
        "\n",
        " > 각 데이터가 의미하는게 무엇인지 잘 보아야 할 것\n",
        "\n",
        " > 가끔 익명화(이해하지 못하는 데이터)가 되어있는 데이터들이 있다. ==> 이것이 무엇을 뜻하는지, 어떤 패턴으로 구성되어있는 것인지, 데이터 타입이 무엇인지 이해하고 FE해야한다.\n",
        "\n",
        "Visualization\n",
        " > 시각화로 데이터를 표현\n",
        "\n",
        " > 데이터의 관계, 통계... 등을 표현 할 수 있다. (scatter, heatmap 유용)\n",
        "\n",
        " > 시각화를 보고 그 어떻게 데이터를 FE할 것인지 전략을 짤 수 있다.\n",
        "\n",
        "Data cleaning\n",
        " > data leakage\n",
        "\n",
        " > 각 데이터에 x.nunique()가 1개 일때는 컬럼 삭제, 중복 삭제(다른 컬럼과 똑같은 데이터의 컬럼이 있으면 삭제하라는 거지?)\n",
        "\n",
        "\n",
        "팁) id가 중복되지 않았는가?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdd-c5D5TLhB"
      },
      "source": [
        "# 확률론적 사고\n",
        "불확실성, 우리가 예상할수 없는 방향으로 간다., 난 답을 모른다(결과), 독립 이해하기, seed설정, 표본설정, 더 많은 시도를 하는게 좋다(표본이 많으면 좋다), 많은시도가 필요하다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcDcc95g3gvU"
      },
      "source": [
        "# 'Will Koehrsen'의 일반적인 데이터분석 순서\n",
        "\n",
        "1. Understand the problem (we're almost there already) - 데이터 이해하기\n",
        "2. Exploratory Data Analysis - EDA(with corr)\n",
        "3. Feature engineering to create a dataset for machine learning - 피쳐 엔지니어링과 모델링\n",
        "4. Compare several baseline machine learning models - 모델 비교\n",
        "5. Try more complex machine learning models - 더 많은 모델\n",
        "6. Optimize the selected model - 모델 최적화\n",
        "7. Investigate model predictions in context of problem - 모델 검증\n",
        "8. Draw conclusions and lay out next steps\n",
        "\n",
        "\n",
        "---\n",
        "# **기업이 원하는 신입**\n",
        "\n",
        "* **데이터로 무장한(SQL, 파이썬, 통계, 머신러닝)**\n",
        "* **발전 가능성 높은**\n",
        "* **조직생활 잘하는**\n"
      ]
    }
  ]
}